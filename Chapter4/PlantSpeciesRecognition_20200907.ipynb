{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PlantSpeciesRecognition_20200907.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHb0htjH3MeC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2814f625-09bf-4459-9971-a43b9445c249"
      },
      "source": [
        "!pip install tensorflow --upgrade --force-reinstall\n",
        "!pip install tf-nightly-gpu\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/ae/0b08f53498417914f2274cc3b5576d2b83179b0cbb209457d0fde0152174/tensorflow-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 48kB/s \n",
            "\u001b[?25hCollecting google-pasta>=0.1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[?25hCollecting absl-py>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/07/f69dd3367368ad69f174bfe426a973651412ec11d48ec05c000f19fe0561/absl_py-0.10.0-py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 48.8MB/s \n",
            "\u001b[?25hCollecting protobuf>=3.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/79/510974552cebff2ba04038544799450defe75e96ea5f1675dbf72cc8744f/protobuf-3.13.0-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 43.7MB/s \n",
            "\u001b[?25hCollecting gast==0.3.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Collecting termcolor>=1.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
            "Collecting wheel>=0.26\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/00/3df031b3ecd5444d572141321537080b40c1c25e1caa3d86cdd12e5e919c/wheel-0.35.1-py2.py3-none-any.whl\n",
            "Collecting grpcio>=1.8.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/61/91641ea993600493d37f4897dc14ef396086868c586869937f6d57479a13/grpcio-1.31.0-cp36-cp36m-manylinux2014_x86_64.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 40.9MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 34.9MB/s \n",
            "\u001b[?25hCollecting scipy==1.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/29/162476fd44203116e7980cfbd9352eef9db37c49445d1fec35509022f6aa/scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1MB)\n",
            "\u001b[K     |████████████████████████████████| 26.1MB 1.5MB/s \n",
            "\u001b[?25hCollecting wrapt>=1.11.1\n",
            "  Downloading https://files.pythonhosted.org/packages/82/f7/e43cefbe88c5fd371f4cf0cf5eb3feccd07515af9fd6cf7dbf1d1793a797/wrapt-1.12.1.tar.gz\n",
            "Collecting six>=1.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/a9/b1bc4c935ed063766bce7d3e8c7b20bd52e515ff1c732b02caacf7918e5a/numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.3MB/s \n",
            "\u001b[?25hCollecting tensorboard<3,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/1b/6a420d7e6ba431cf3d51b2a5bfa06a958c4141e3189385963dc7f6fbffb6/tensorboard-2.3.0-py3-none-any.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 41.6MB/s \n",
            "\u001b[?25hCollecting astunparse==1.6.3\n",
            "  Downloading https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 38.9MB/s \n",
            "\u001b[?25hCollecting keras-preprocessing<1.2,>=1.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[?25hCollecting setuptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/a6/7fb6e8b3f4a6051e72e4e2218889351f0ee484b9ee17e995f5ccff780300/setuptools-50.3.0-py3-none-any.whl (785kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 41.2MB/s \n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
            "Collecting markdown>=2.6.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/63/eaec2bd025ab48c754b55e8819af0f6a69e2b1e187611dd40cbbe101ee7f/Markdown-3.2.2-py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.1MB/s \n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/85/5c5ac0a8c5efdfab916e9c6bc18963f6a6996a8a1e19ec4ad8c9ac9c623c/tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 24.8MB/s \n",
            "\u001b[?25hCollecting werkzeug>=0.11.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl (298kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 48.9MB/s \n",
            "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/37/a21382309d6cd433d6f002a683bc4f2e27ad912af11d4c4a7bdd6e8d363d/google_auth-1.21.1-py2.py3-none-any.whl (93kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.9MB/s \n",
            "\u001b[?25hCollecting requests<3,>=2.21.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.8MB/s \n",
            "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
            "Collecting importlib-metadata; python_version < \"3.8\"\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/58/cdea07eb51fc2b906db0968a94700866fc46249bdc75cac23f9d13168929/importlib_metadata-1.7.0-py2.py3-none-any.whl\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 37.7MB/s \n",
            "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/5c/f3aa86b6d5482f3051b433c7616668a9b96fbe49a622210e2c9781938a5c/cachetools-4.1.1-py3-none-any.whl\n",
            "Collecting rsa<5,>=3.1.4; python_version >= \"3.5\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/df/c3587a667d6b308fadc90b99e8bc8774788d033efcc70f4ecaae7fad144b/rsa-4.6-py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/c4/6c4fe722df5343c33226f0b4e0bb042e4dc13483228b4718baf286f86d87/certifi-2020.6.20-py2.py3-none-any.whl (156kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 50.1MB/s \n",
            "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/f0/a391d1463ebb1b233795cabfc0ef38d3db4442339de68f847026199e69d7/urllib3-1.25.10-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 46.3MB/s \n",
            "\u001b[?25hCollecting idna<3,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/38/928ddce2273eaa564f6f50de919327bf3a00f091b5baba8dfa9460f3a8a8/idna-2.10-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.7MB/s \n",
            "\u001b[?25hCollecting chardet<4,>=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 42.2MB/s \n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 48.0MB/s \n",
            "\u001b[?25hCollecting zipp>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/34/bfcb43cc0ba81f527bc4f40ef41ba2ff4080e047acb0586b56b3d017ace4/zipp-3.1.0-py3-none-any.whl\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: termcolor, wrapt\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-cp36-none-any.whl size=4832 sha256=367eae8911ee91f11bf27812bc1ec76eb4da0105cb17ec334202d9c938497690\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=67506 sha256=e44a0dfcd8944d800cf27a70147914ecc1fe42ac2d5c67a14fb0ba0247157e81\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c2/ed/d62208260edbd3fa7156545c00ef966f45f2063d0a84f8208a\n",
            "Successfully built termcolor wrapt\n",
            "\u001b[31mERROR: tensorflow-metadata 0.23.0 has requirement absl-py<0.9,>=0.7, but you'll have absl-py 0.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kaggle 1.5.6 has requirement urllib3<1.25,>=1.21.1, but you'll have urllib3 1.25.10 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.17.2, but you'll have google-auth 1.21.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.24.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, google-pasta, numpy, opt-einsum, absl-py, setuptools, protobuf, gast, termcolor, wheel, grpcio, tensorflow-estimator, scipy, wrapt, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, certifi, urllib3, idna, chardet, requests, oauthlib, requests-oauthlib, google-auth-oauthlib, zipp, importlib-metadata, markdown, tensorboard-plugin-wit, werkzeug, tensorboard, astunparse, h5py, keras-preprocessing, tensorflow\n",
            "  Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Found existing installation: google-pasta 0.2.0\n",
            "    Uninstalling google-pasta-0.2.0:\n",
            "      Successfully uninstalled google-pasta-0.2.0\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: opt-einsum 3.3.0\n",
            "    Uninstalling opt-einsum-3.3.0:\n",
            "      Successfully uninstalled opt-einsum-3.3.0\n",
            "  Found existing installation: absl-py 0.8.1\n",
            "    Uninstalling absl-py-0.8.1:\n",
            "      Successfully uninstalled absl-py-0.8.1\n",
            "  Found existing installation: setuptools 49.6.0\n",
            "    Uninstalling setuptools-49.6.0:\n",
            "      Successfully uninstalled setuptools-49.6.0\n",
            "  Found existing installation: protobuf 3.12.4\n",
            "    Uninstalling protobuf-3.12.4:\n",
            "      Successfully uninstalled protobuf-3.12.4\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: termcolor 1.1.0\n",
            "    Uninstalling termcolor-1.1.0:\n",
            "      Successfully uninstalled termcolor-1.1.0\n",
            "  Found existing installation: wheel 0.35.1\n",
            "    Uninstalling wheel-0.35.1:\n",
            "      Successfully uninstalled wheel-0.35.1\n",
            "  Found existing installation: grpcio 1.31.0\n",
            "    Uninstalling grpcio-1.31.0:\n",
            "      Successfully uninstalled grpcio-1.31.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: wrapt 1.12.1\n",
            "    Uninstalling wrapt-1.12.1:\n",
            "      Successfully uninstalled wrapt-1.12.1\n",
            "  Found existing installation: pyasn1 0.4.8\n",
            "    Uninstalling pyasn1-0.4.8:\n",
            "      Successfully uninstalled pyasn1-0.4.8\n",
            "  Found existing installation: pyasn1-modules 0.2.8\n",
            "    Uninstalling pyasn1-modules-0.2.8:\n",
            "      Successfully uninstalled pyasn1-modules-0.2.8\n",
            "  Found existing installation: cachetools 4.1.1\n",
            "    Uninstalling cachetools-4.1.1:\n",
            "      Successfully uninstalled cachetools-4.1.1\n",
            "  Found existing installation: rsa 4.6\n",
            "    Uninstalling rsa-4.6:\n",
            "      Successfully uninstalled rsa-4.6\n",
            "  Found existing installation: google-auth 1.17.2\n",
            "    Uninstalling google-auth-1.17.2:\n",
            "      Successfully uninstalled google-auth-1.17.2\n",
            "  Found existing installation: certifi 2020.6.20\n",
            "    Uninstalling certifi-2020.6.20:\n",
            "      Successfully uninstalled certifi-2020.6.20\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: oauthlib 3.1.0\n",
            "    Uninstalling oauthlib-3.1.0:\n",
            "      Successfully uninstalled oauthlib-3.1.0\n",
            "  Found existing installation: requests-oauthlib 1.3.0\n",
            "    Uninstalling requests-oauthlib-1.3.0:\n",
            "      Successfully uninstalled requests-oauthlib-1.3.0\n",
            "  Found existing installation: google-auth-oauthlib 0.4.1\n",
            "    Uninstalling google-auth-oauthlib-0.4.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.1\n",
            "  Found existing installation: zipp 3.1.0\n",
            "    Uninstalling zipp-3.1.0:\n",
            "      Successfully uninstalled zipp-3.1.0\n",
            "  Found existing installation: importlib-metadata 1.7.0\n",
            "    Uninstalling importlib-metadata-1.7.0:\n",
            "      Successfully uninstalled importlib-metadata-1.7.0\n",
            "  Found existing installation: Markdown 3.2.2\n",
            "    Uninstalling Markdown-3.2.2:\n",
            "      Successfully uninstalled Markdown-3.2.2\n",
            "  Found existing installation: tensorboard-plugin-wit 1.7.0\n",
            "    Uninstalling tensorboard-plugin-wit-1.7.0:\n",
            "      Successfully uninstalled tensorboard-plugin-wit-1.7.0\n",
            "  Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: astunparse 1.6.3\n",
            "    Uninstalling astunparse-1.6.3:\n",
            "      Successfully uninstalled astunparse-1.6.3\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed absl-py-0.10.0 astunparse-1.6.3 cachetools-4.1.1 certifi-2020.6.20 chardet-3.0.4 gast-0.3.3 google-auth-1.21.1 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.31.0 h5py-2.10.0 idna-2.10 importlib-metadata-1.7.0 keras-preprocessing-1.1.2 markdown-3.2.2 numpy-1.18.5 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.13.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.24.0 requests-oauthlib-1.3.0 rsa-4.6 scipy-1.4.1 setuptools-50.3.0 six-1.15.0 tensorboard-2.3.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.0 tensorflow-estimator-2.3.0 termcolor-1.1.0 urllib3-1.25.10 werkzeug-1.0.1 wheel-0.35.1 wrapt-1.12.1 zipp-3.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy",
                  "pkg_resources",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/8e/f564a367296870fe94caa94ea362bed653eac1d32b63d96c6c29456bcab2/tf_nightly_gpu-2.4.0.dev20200906-cp36-cp36m-manylinux2010_x86_64.whl (341.4MB)\n",
            "\u001b[K     |████████████████████████████████| 341.4MB 50kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.18.5)\n",
            "Collecting tf-estimator-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/3e/a73c53e409cc0129efd6c1d60c7d792a79ce9411973ad0e1761b7f507ea3/tf_estimator_nightly-2.4.0.dev2020090601-py2.py3-none-any.whl (460kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 31.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (3.7.4.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.35.1)\n",
            "Collecting flatbuffers>=1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/26/712e578c5f14e26ae3314c39a1bdc4eb2ec2f4ddc89b708cf8e0a0d20423/flatbuffers-1.12-py2.py3-none-any.whl\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.10.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (2.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.12.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.2.0)\n",
            "Collecting tb-nightly<3.0.0a0,>=2.4.0a0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/5b/59351ae309dc3fb895e098169d2f860ae84cf22dba10303b0e2e4789e2f4/tb_nightly-2.4.0a20200906-py3-none-any.whl (9.2MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2MB 43.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.31.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (3.13.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (50.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (1.21.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (2.24.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (1.7.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (1.25.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly-gpu) (0.4.8)\n",
            "Installing collected packages: tf-estimator-nightly, flatbuffers, tb-nightly, tf-nightly-gpu\n",
            "Successfully installed flatbuffers-1.12 tb-nightly-2.4.0a20200906 tf-estimator-nightly-2.4.0.dev2020090601 tf-nightly-gpu-2.4.0.dev20200906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-Jp2gUn4Ee5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d392a80b-0eab-4836-99bb-601f3435ce3d"
      },
      "source": [
        "_URL = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "\n",
        "zip_file = tf.keras.utils.get_file(origin=_URL, \n",
        "                                   fname=\"flower_photos.tgz\", \n",
        "                                   extract=True, cache_subdir='/content',)\n",
        "\n",
        "base_dir = os.path.join(os.path.dirname(zip_file), 'flower_photos')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228818944/228813984 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qjtbcIK4MOX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2157d550-295d-4c89-8309-72fead8ca110"
      },
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    validation_split=0.2)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='training')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2939 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDl9M89Z4QfH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "feb69214-6883-4f37-f786-bf58a137e855"
      },
      "source": [
        "val_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='validation')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 731 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2jhdBwr4lWH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46071b33-f84c-440c-ec84-ef97d56ecbae"
      },
      "source": [
        "for image_batch, label_batch in train_generator:\n",
        "  break\n",
        "image_batch.shape, label_batch.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((64, 224, 224, 3), (64, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjyadJCR4o5n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4ce54ad-fe6a-4cbc-bac6-16894234f2f3"
      },
      "source": [
        "print(train_generator.class_indices)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsaUi_6M4ssc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write(labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pN3NZOV4x-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "bf4ff60a-1a17-419a-97f1-46d425d608b6"
      },
      "source": [
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi2Lstmj44yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dr136so48MQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "      base_model,\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(5, activation='softmax')\n",
        "])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjZ8rG2X5Bow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk_sY4TH5Fr4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1847e4be-fa59-4aa4-b926-8dbf50864ee1"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs=epochs, \n",
        "                    validation_data=val_generator)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "46/46 [==============================] - 150s 3s/step - loss: 1.6037 - accuracy: 0.5440 - val_loss: 0.6786 - val_accuracy: 0.7209\n",
            "Epoch 2/10\n",
            "46/46 [==============================] - 146s 3s/step - loss: 0.5480 - accuracy: 0.7514 - val_loss: 0.5371 - val_accuracy: 0.8140\n",
            "Epoch 3/10\n",
            "46/46 [==============================] - 145s 3s/step - loss: 0.3228 - accuracy: 0.8904 - val_loss: 0.4168 - val_accuracy: 0.8495\n",
            "Epoch 4/10\n",
            "46/46 [==============================] - 145s 3s/step - loss: 0.1937 - accuracy: 0.9423 - val_loss: 0.4919 - val_accuracy: 0.8440\n",
            "Epoch 5/10\n",
            "46/46 [==============================] - 145s 3s/step - loss: 0.1257 - accuracy: 0.9664 - val_loss: 0.4388 - val_accuracy: 0.8523\n",
            "Epoch 6/10\n",
            "46/46 [==============================] - 144s 3s/step - loss: 0.0960 - accuracy: 0.9723 - val_loss: 0.4509 - val_accuracy: 0.8591\n",
            "Epoch 7/10\n",
            "46/46 [==============================] - 145s 3s/step - loss: 0.0601 - accuracy: 0.9881 - val_loss: 0.4610 - val_accuracy: 0.8509\n",
            "Epoch 8/10\n",
            "46/46 [==============================] - 145s 3s/step - loss: 0.0464 - accuracy: 0.9898 - val_loss: 0.4924 - val_accuracy: 0.8509\n",
            "Epoch 9/10\n",
            "46/46 [==============================] - 146s 3s/step - loss: 0.0343 - accuracy: 0.9940 - val_loss: 0.4993 - val_accuracy: 0.8509\n",
            "Epoch 10/10\n",
            "46/46 [==============================] - 145s 3s/step - loss: 0.0295 - accuracy: 0.9970 - val_loss: 0.5045 - val_accuracy: 0.8564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5hGSunwbrkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "654760da-0437-427a-d876-ebde8fb3b606"
      },
      "source": [
        "saved_model_dir = ''\n",
        "tf.saved_model.save(model, saved_model_dir)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:109: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:109: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbWWZtt0b6b7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJI9BxbEcDc7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "166ace08-48b8-4f90-c6ad-387881e443f0"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model.tflite')\n",
        "files.download('labels.txt')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5c2d5861-1858-469a-bdae-e2f0cd66c99e\", \"model.tflite\", 10378468)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7939bf27-2b1d-4011-8c1e-721d482d098a\", \"labels.txt\", 39)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}